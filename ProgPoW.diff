diff --git a/cmd/puppeth/genesis.go b/cmd/puppeth/genesis.go
index ae7675cd9..c36777b33 100644
--- a/cmd/puppeth/genesis.go
+++ b/cmd/puppeth/genesis.go
@@ -218,6 +218,7 @@ type parityChainSpec struct {
 				DifficultyBombDelays   map[string]string `json:"difficultyBombDelays"`
 				HomesteadTransition    hexutil.Uint64    `json:"homesteadTransition"`
 				EIP100bTransition      hexutil.Uint64    `json:"eip100bTransition"`
+				ProgpowTransition      *hexutil.Uint64   `json:"progpowTransition,omitempty"`
 			} `json:"params"`
 		} `json:"Ethash"`
 	} `json:"engine"`
@@ -352,7 +353,11 @@ func newParityChainSpec(network string, genesis *core.Genesis, bootnodes []strin
 	if num := genesis.Config.PetersburgBlock; num != nil {
 		spec.setConstantinopleFix(num)
 	}
-
+	// Progpow
+	if num := genesis.Config.ProgpowBlock; num != nil {
+		hexnum := hexutil.Uint64(num.Uint64())
+		spec.Engine.Ethash.Params.ProgpowTransition = &hexnum
+	}
 	spec.Params.MaximumExtraDataSize = (hexutil.Uint64)(params.MaximumExtraDataSize)
 	spec.Params.MinGasLimit = (hexutil.Uint64)(params.MinGasLimit)
 	spec.Params.GasLimitBoundDivisor = (math2.HexOrDecimal64)(params.GasLimitBoundDivisor)
diff --git a/cmd/puppeth/module_dashboard.go b/cmd/puppeth/module_dashboard.go
index 9a77587b4..78f8f9f17 100644
--- a/cmd/puppeth/module_dashboard.go
+++ b/cmd/puppeth/module_dashboard.go
@@ -633,6 +633,7 @@ func deployDashboard(client *sshClient, network string, conf *config, config *da
 		"Byzantium":         conf.Genesis.Config.ByzantiumBlock,
 		"Constantinople":    conf.Genesis.Config.ConstantinopleBlock,
 		"ConstantinopleFix": conf.Genesis.Config.PetersburgBlock,
+		"ProgPoW":           conf.Genesis.Config.ProgpowBlock,
 	})
 	files[filepath.Join(workdir, "index.html")] = indexfile.Bytes()
 
diff --git a/cmd/puppeth/wizard_genesis.go b/cmd/puppeth/wizard_genesis.go
index 6aed09f14..ab8763078 100644
--- a/cmd/puppeth/wizard_genesis.go
+++ b/cmd/puppeth/wizard_genesis.go
@@ -229,6 +229,12 @@ func (w *wizard) manageGenesis() {
 		fmt.Printf("Which block should Constantinople-Fix (remove EIP-1283) come into effect? (default = %v)\n", w.conf.Genesis.Config.PetersburgBlock)
 		w.conf.Genesis.Config.PetersburgBlock = w.readDefaultBigInt(w.conf.Genesis.Config.PetersburgBlock)
 
+		if w.conf.Genesis.Config.Clique == nil {
+			fmt.Println()
+			fmt.Printf("Which block should ProgPow come into effect? (default = %v)\n", w.conf.Genesis.Config.ProgpowBlock)
+			w.conf.Genesis.Config.ProgpowBlock = w.readDefaultBigInt(w.conf.Genesis.Config.ProgpowBlock)
+		}
+
 		out, _ := json.MarshalIndent(w.conf.Genesis.Config, "", "  ")
 		fmt.Printf("Chain configuration updated:\n\n%s\n", out)
 
diff --git a/cmd/utils/flags.go b/cmd/utils/flags.go
index 5b8ebb481..1b235254f 100644
--- a/cmd/utils/flags.go
+++ b/cmd/utils/flags.go
@@ -1579,6 +1579,7 @@ func MakeChain(ctx *cli.Context, stack *node.Node) (chain *core.BlockChain, chai
 				DatasetDir:     stack.ResolvePath(eth.DefaultConfig.Ethash.DatasetDir),
 				DatasetsInMem:  eth.DefaultConfig.Ethash.DatasetsInMem,
 				DatasetsOnDisk: eth.DefaultConfig.Ethash.DatasetsOnDisk,
+				ProgpowBlock:   config.ProgpowBlock,
 			}, nil, false)
 		}
 	}
diff --git a/consensus/ethash/algorithm.go b/consensus/ethash/algorithm.go
index d6c871092..44cc2db82 100644
--- a/consensus/ethash/algorithm.go
+++ b/consensus/ethash/algorithm.go
@@ -207,6 +207,27 @@ func generateCache(dest []uint32, epoch uint64, seed []byte) {
 	}
 }
 
+// generateCDag generates the cDag used for progpow. If the 'cDag' is nil, this method is a no-op. Otherwise
+// it expects the cDag to be of size progpowCacheWords
+func generateCDag(cDag, cache []uint32, epoch uint64) {
+	if cDag == nil {
+		return
+	}
+	start := time.Now()
+	keccak512 := makeHasher(sha3.NewLegacyKeccak512())
+
+	for i := uint32(0); i < progpowCacheWords/16; i++ {
+		rawData := generateDatasetItem(cache, i, keccak512)
+		// 64 bytes in rawData -> 16 uint32
+		for j := uint32(0); j < 16; j++ {
+			cDag[i*16+j] = binary.LittleEndian.Uint32(rawData[4*j:])
+		}
+	}
+
+	elapsed := time.Since(start)
+	log.Info("Generated progpow cDag", "elapsed", common.PrettyDuration(elapsed), "epoch", epoch)
+}
+
 // swap changes the byte order of the buffer assuming a uint32 representation.
 func swap(buffer []byte) {
 	for i := 0; i < len(buffer); i += 4 {
diff --git a/consensus/ethash/algorithm_test.go b/consensus/ethash/algorithm_test.go
index c58479e28..38a04c665 100644
--- a/consensus/ethash/algorithm_test.go
+++ b/consensus/ethash/algorithm_test.go
@@ -729,7 +729,7 @@ func TestConcurrentDiskCacheGeneration(t *testing.T) {
 
 		go func(idx int) {
 			defer pend.Done()
-			ethash := New(Config{cachedir, 0, 1, "", 0, 0, ModeNormal}, nil, false)
+			ethash := New(Config{cachedir, 0, 1, "", 0, 0, ModeNormal, nil}, nil, false)
 			defer ethash.Close()
 			if err := ethash.VerifySeal(nil, block.Header()); err != nil {
 				t.Errorf("proc %d: block verification failed: %v", idx, err)
@@ -739,7 +739,7 @@ func TestConcurrentDiskCacheGeneration(t *testing.T) {
 	pend.Wait()
 }
 
-// Benchmarks the cache generation performance.
+// BenchmarkCacheGeneration benchmarks the cache generation performance.
 func BenchmarkCacheGeneration(b *testing.B) {
 	for i := 0; i < b.N; i++ {
 		cache := make([]uint32, cacheSize(1)/4)
@@ -747,7 +747,7 @@ func BenchmarkCacheGeneration(b *testing.B) {
 	}
 }
 
-// Benchmarks the dataset (small) generation performance.
+// BenchmarkSmallDatasetGeneration benchmarks the dataset (small) generation performance.
 func BenchmarkSmallDatasetGeneration(b *testing.B) {
 	cache := make([]uint32, 65536/4)
 	generateCache(cache, 0, make([]byte, 32))
@@ -759,7 +759,7 @@ func BenchmarkSmallDatasetGeneration(b *testing.B) {
 	}
 }
 
-// Benchmarks the light verification performance.
+// BenchmarkHashimotoLight benchmarks the light verification performance.
 func BenchmarkHashimotoLight(b *testing.B) {
 	cache := make([]uint32, cacheSize(1)/4)
 	generateCache(cache, 0, make([]byte, 32))
@@ -772,7 +772,22 @@ func BenchmarkHashimotoLight(b *testing.B) {
 	}
 }
 
-// Benchmarks the full (small) verification performance.
+// BenchmarkProgpowLight benchmarks the light verification performance (not counting cDag generation).
+func BenchmarkProgpowLight(b *testing.B) {
+	cache := make([]uint32, cacheSize(1)/4)
+	generateCache(cache, 0, make([]byte, 32))
+
+	hash := hexutil.MustDecode("0xc9149cc0386e689d789a1c2f3d5d169a61a6218ed30e74414dc736e442ef3d1f")
+	cDag := make([]uint32, progpowCacheWords)
+	generateCDag(cDag, cache, 0)
+
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		progpowLight(datasetSize(1), cache, hash, 0, 0, cDag)
+	}
+}
+
+// BenchmarkHashimotoFullSmall benchmarks the full (small) verification performance.
 func BenchmarkHashimotoFullSmall(b *testing.B) {
 	cache := make([]uint32, 65536/4)
 	generateCache(cache, 0, make([]byte, 32))
@@ -787,3 +802,19 @@ func BenchmarkHashimotoFullSmall(b *testing.B) {
 		hashimotoFull(dataset, hash, 0)
 	}
 }
+
+// BenchmarkProgpowFullSmall benchmarks the full (small) verification performance.
+func BenchmarkProgpowFullSmall(b *testing.B) {
+	cache := make([]uint32, 65536/4)
+	generateCache(cache, 0, make([]byte, 32))
+
+	dataset := make([]uint32, 32*65536/4)
+	generateDataset(dataset, 0, cache)
+
+	hash := hexutil.MustDecode("0xc9149cc0386e689d789a1c2f3d5d169a61a6218ed30e74414dc736e442ef3d1f")
+
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		progpowFull(dataset, hash, 0, 0)
+	}
+}
diff --git a/consensus/ethash/consensus.go b/consensus/ethash/consensus.go
index 62e3f8fca..21c3d99d9 100644
--- a/consensus/ethash/consensus.go
+++ b/consensus/ethash/consensus.go
@@ -509,14 +509,16 @@ func (ethash *Ethash) verifySeal(chain consensus.ChainReader, header *types.Head
 	number := header.Number.Uint64()
 
 	var (
-		digest []byte
-		result []byte
+		digest   []byte
+		result   []byte
+		powLight = ethash.lightPow(header.Number)
+		powFull  = ethash.fullPow(header.Number)
 	)
 	// If fast-but-heavy PoW verification was requested, use an ethash dataset
 	if fulldag {
 		dataset := ethash.dataset(number, true)
 		if dataset.generated() {
-			digest, result = hashimotoFull(dataset.dataset, ethash.SealHash(header).Bytes(), header.Nonce.Uint64())
+			digest, result = powFull(dataset.dataset, ethash.SealHash(header).Bytes(), header.Nonce.Uint64(), number)
 
 			// Datasets are unmapped in a finalizer. Ensure that the dataset stays alive
 			// until after the call to hashimotoFull so it's not unmapped while being used.
@@ -534,7 +536,7 @@ func (ethash *Ethash) verifySeal(chain consensus.ChainReader, header *types.Head
 		if ethash.config.PowMode == ModeTest {
 			size = 32 * 1024
 		}
-		digest, result = hashimotoLight(size, cache.cache, ethash.SealHash(header).Bytes(), header.Nonce.Uint64())
+		digest, result = powLight(size, cache.cache, ethash.SealHash(header).Bytes(), header.Nonce.Uint64(), number)
 
 		// Caches are unmapped in a finalizer. Ensure that the cache stays alive
 		// until after the call to hashimotoLight so it's not unmapped while being used.
diff --git a/consensus/ethash/consensus_test.go b/consensus/ethash/consensus_test.go
index 438a99dd6..3e99d4d65 100644
--- a/consensus/ethash/consensus_test.go
+++ b/consensus/ethash/consensus_test.go
@@ -84,3 +84,81 @@ func TestCalcDifficulty(t *testing.T) {
 		}
 	}
 }
+
+//func TestTransitionToProgpow(t *testing.T) {
+//	fn := filepath.Join("..", "..", "tests", "hashi_to_pp_at_5.rlp.gz")
+//	fh, err := os.Open(fn)
+//	if err != nil {
+//		t.Skip(err)
+//	}
+//	defer fh.Close()
+//
+//	var reader io.Reader = fh
+//	if strings.HasSuffix(fn, ".gz") {
+//		if reader, err = gzip.NewReader(reader); err != nil {
+//			t.Skip(err)
+//		}
+//	}
+//	stream := rlp.NewStream(reader, 0)
+//	config := &params.ChainConfig{
+//		HomesteadBlock: big.NewInt(1),
+//		EIP150Block:    big.NewInt(2),
+//		EIP155Block:    big.NewInt(3),
+//		EIP158Block:    big.NewInt(3),
+//		ProgpowBlock:   big.NewInt(5),
+//	}
+//	genesis := core.Genesis{Config: config,
+//		GasLimit:  0x47b760,
+//		Alloc:     core.GenesisAlloc{},
+//		Timestamp: 0x59a4e76d,
+//		ExtraData: hexutil.MustDecode("0x0000000000000000000000000000000000000000000000000000000000000000"),
+//	}
+//	db := ethdb.NewMemDatabase()
+//	genesis.MustCommit(db)
+//
+//	engine := New(Config{
+//		CacheDir:           "",
+//		CachesInMem:        1,
+//		CachesOnDisk:       1,
+//		DatasetDir:         "",
+//		DatasetsInMem:      1,
+//		DatasetsOnDisk:     1,
+//		ProgpowBlock: config.ProgpowBlock,
+//	}, nil, false)
+//	bc, err := core.NewBlockChain(db, nil, config, engine, vm.Config{}, nil)
+//	//fmt.Printf("Genesis hash %x\n", bc.Genesis().Hash())
+//	if err != nil {
+//		t.Skip(err)
+//	}
+//	blocks := make(types.Blocks, 100)
+//	n := 0
+//	for batch := 0; ; batch++ {
+//		// Load a batch of RLP blocks.
+//		i := 0
+//		for ; i < 100; i++ {
+//			var b types.Block
+//			if err := stream.Decode(&b); err == io.EOF {
+//				break
+//			} else if err != nil {
+//				t.Errorf("at block %d: %v", n, err)
+//			}
+//			// don't import first block
+//			if b.NumberU64() == 0 {
+//				i--
+//				continue
+//			}
+//			blocks[i] = &b
+//			n++
+//		}
+//		if i == 0 {
+//			break
+//		}
+//		if _, err := bc.InsertChain(blocks[:i]); err != nil {
+//			t.Fatalf("invalid block %d: %v", n, err)
+//		}
+//	}
+//	if bc.CurrentBlock().Number().Cmp(big.NewInt(1054)) != 0 {
+//		t.Errorf("Expected to import 1054 blocks, got %v", bc.CurrentBlock().Number())
+//
+//	}
+//}
diff --git a/consensus/ethash/ethash.go b/consensus/ethash/ethash.go
index 78892e1da..5fa9bdded 100644
--- a/consensus/ethash/ethash.go
+++ b/consensus/ethash/ethash.go
@@ -18,6 +18,7 @@
 package ethash
 
 import (
+	"encoding/binary"
 	"errors"
 	"fmt"
 	"math"
@@ -49,8 +50,9 @@ var (
 	// two256 is a big integer representing 2^256
 	two256 = new(big.Int).Exp(big.NewInt(2), big.NewInt(256), big.NewInt(0))
 
-	// sharedEthash is a full instance that can be shared between multiple users.
-	sharedEthash = New(Config{"", 3, 0, "", 1, 0, ModeNormal}, nil, false)
+	// sharedEngines contains ethash instances which are mapped by progpow blocknumber
+	sharedEngines map[uint64]*Ethash
+	ethashMu      sync.Mutex // lock for modifying sharedEngines
 
 	// algorithmRevision is the data structure version used for file naming.
 	algorithmRevision = 23
@@ -205,6 +207,7 @@ type cache struct {
 	dump  *os.File  // File descriptor of the memory mapped cache
 	mmap  mmap.MMap // Memory map itself to unmap before releasing
 	cache []uint32  // The actual cache data content (may be memory mapped)
+	cDag  []uint32  // The cDag used by progpow. May be nil
 	once  sync.Once // Ensures the cache is generated only once
 }
 
@@ -226,6 +229,8 @@ func (c *cache) generate(dir string, limit int, test bool) {
 		if dir == "" {
 			c.cache = make([]uint32, size/4)
 			generateCache(c.cache, c.epoch, seed)
+			c.cDag = make([]uint32, progpowCacheWords)
+			generateCDag(c.cDag, c.cache, c.epoch)
 			return
 		}
 		// Disk storage is needed, this will get fancy
@@ -245,6 +250,8 @@ func (c *cache) generate(dir string, limit int, test bool) {
 		c.dump, c.mmap, c.cache, err = memoryMap(path)
 		if err == nil {
 			logger.Debug("Loaded old ethash cache from disk")
+			c.cDag = make([]uint32, progpowCacheWords)
+			generateCDag(c.cDag, c.cache, c.epoch)
 			return
 		}
 		logger.Debug("Failed to load old ethash cache", "err", err)
@@ -257,6 +264,8 @@ func (c *cache) generate(dir string, limit int, test bool) {
 			c.cache = make([]uint32, size/4)
 			generateCache(c.cache, c.epoch, seed)
 		}
+		c.cDag = make([]uint32, progpowCacheWords)
+		generateCDag(c.cDag, c.cache, c.epoch)
 		// Iterate over all previous instances and delete old ones
 		for ep := int(c.epoch) - limit; ep >= 0; ep-- {
 			seed := seedHash(uint64(ep)*epochLength + 1)
@@ -403,6 +412,7 @@ type Config struct {
 	DatasetsInMem  int
 	DatasetsOnDisk int
 	PowMode        Mode
+	ProgpowBlock   *big.Int // Block number at which to use progpow instead of hashimoto
 }
 
 // sealTask wraps a seal block with relative result channel for remote sealer thread.
@@ -564,8 +574,15 @@ func NewFullFaker() *Ethash {
 
 // NewShared creates a full sized ethash PoW shared between all requesters running
 // in the same process.
-func NewShared() *Ethash {
-	return &Ethash{shared: sharedEthash}
+func NewShared(progpowNumber *big.Int) *Ethash {
+	ethashMu.Lock()
+	sharedEngine, exist := sharedEngines[progpowNumber.Uint64()]
+	if !exist {
+		sharedEngine = New(Config{"", 3, 0, "", 1, 0, ModeNormal, progpowNumber}, nil, false)
+		sharedEngines[progpowNumber.Uint64()] = sharedEngine
+	}
+	ethashMu.Unlock()
+	return &Ethash{shared: sharedEngine}
 }
 
 // Close closes the exit channel to notify all backend threads exiting.
@@ -715,3 +732,51 @@ func (ethash *Ethash) APIs(chain consensus.ChainReader) []rpc.API {
 func SeedHash(block uint64) []byte {
 	return seedHash(block)
 }
+
+type powFull func(dataset []uint32, hash []byte, nonce, number uint64) ([]byte, []byte)
+type powLight func(size uint64, cache []uint32, hash []byte, nonce, number uint64) ([]byte, []byte)
+
+// fullPow returns either hashimoto or progpow full checker depending on number
+func (ethash *Ethash) fullPow(number *big.Int) powFull {
+	if progpowNumber := ethash.config.ProgpowBlock; progpowNumber != nil && progpowNumber.Cmp(number) <= 0 {
+		ethashCache := ethash.cache(number.Uint64())
+		if ethashCache.cDag == nil {
+			log.Warn("cDag is nil, suboptimal performance")
+			cDag := make([]uint32, progpowCacheWords)
+			generateCDag(cDag, ethashCache.cache, number.Uint64()/epochLength)
+			ethashCache.cDag = cDag
+		}
+		mix := make([]byte, hashBytes)
+		return func(dataset []uint32, hash []byte, nonce, number uint64) ([]byte, []byte) {
+			lookup := func(index uint32) []byte {
+				for i := uint32(0); i < hashWords; i++ {
+					binary.LittleEndian.PutUint32(mix[i*4:], dataset[index+i])
+				}
+				return mix
+			}
+			return progpow(hash, nonce, uint64(len(dataset))*4, number, ethashCache.cDag, lookup)
+		}
+	}
+	return func(dataset []uint32, hash []byte, nonce uint64, number uint64) ([]byte, []byte) {
+		return hashimotoFull(dataset, hash, nonce)
+	}
+}
+
+// lightPow returns either hashimoto or progpow depending on number
+func (ethash *Ethash) lightPow(number *big.Int) powLight {
+	if progpowNumber := ethash.config.ProgpowBlock; progpowNumber != nil && progpowNumber.Cmp(number) <= 0 {
+		return func(size uint64, cache []uint32, hash []byte, nonce uint64, blockNumber uint64) ([]byte, []byte) {
+			ethashCache := ethash.cache(blockNumber)
+			if ethashCache.cDag == nil {
+				log.Warn("cDag is nil, suboptimal performance")
+				cDag := make([]uint32, progpowCacheWords)
+				generateCDag(cDag, ethashCache.cache, blockNumber/epochLength)
+				ethashCache.cDag = cDag
+			}
+			return progpowLight(size, cache, hash, nonce, blockNumber, ethashCache.cDag)
+		}
+	}
+	return func(size uint64, cache []uint32, hash []byte, nonce uint64, blockNumber uint64) ([]byte, []byte) {
+		return hashimotoLight(size, cache, hash, nonce)
+	}
+}
diff --git a/consensus/ethash/progpow.go b/consensus/ethash/progpow.go
new file mode 100644
index 000000000..b81b73208
--- /dev/null
+++ b/consensus/ethash/progpow.go
@@ -0,0 +1,431 @@
+// Copyright 2019 The go-ethereum Authors
+// This file is part of the go-ethereum library.
+//
+// The go-ethereum library is free software: you can redistribute it and/or modify
+// it under the terms of the GNU Lesser General Public License as published by
+// the Free Software Foundation, either version 3 of the License, or
+// (at your option) any later version.
+//
+// The go-ethereum library is distributed in the hope that it will be useful,
+// but WITHOUT ANY WARRANTY; without even the implied warranty of
+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+// GNU Lesser General Public License for more details.
+//
+// You should have received a copy of the GNU Lesser General Public License
+// along with the go-ethereum library. If not, see <http://www.gnu.org/licenses/>.
+
+// Package ethash implements the ethash proof-of-work consensus engine.
+package ethash
+
+import (
+	"encoding/binary"
+	"math/bits"
+
+	"golang.org/x/crypto/sha3"
+)
+
+const (
+	progpowCacheBytes   = 16 * 1024             // Total size 16*1024 bytes
+	progpowCacheWords   = progpowCacheBytes / 4 // Total size 16*1024 bytes
+	progpowLanes        = 16                    // The number of parallel lanes that coordinate to calculate a single hash instance.
+	progpowRegs         = 32                    // The register file usage size
+	progpowDagLoads     = 4                     // Number of uint32 loads from the DAG per lane
+	progpowCntCache     = 12
+	progpowCntMath      = 20
+	progpowPeriodLength = 50           // Blocks per progpow epoch (N)
+	progpowCntDag       = loopAccesses // Number of DAG accesses, same as ethash (64)
+	progpowMixBytes     = 2 * mixBytes
+)
+
+func progpowLight(size uint64, cache []uint32, hash []byte, nonce uint64, blockNumber uint64, cDag []uint32) ([]byte, []byte) {
+	keccak512 := makeHasher(sha3.NewLegacyKeccak512())
+	lookup := func(index uint32) []byte {
+		return generateDatasetItem(cache, index/16, keccak512)
+	}
+	return progpow(hash, nonce, size, blockNumber, cDag, lookup)
+}
+
+func progpowFull(dataset []uint32, hash []byte, nonce uint64, blockNumber uint64) ([]byte, []byte) {
+	lookup := func(index uint32) []byte {
+		mix := make([]byte, hashBytes)
+		for i := uint32(0); i < hashWords; i++ {
+			binary.LittleEndian.PutUint32(mix[i*4:], dataset[index+i])
+		}
+		return mix
+	}
+	cDag := make([]uint32, progpowCacheBytes/4)
+	for i := uint32(0); i < progpowCacheBytes/4; i += 2 {
+		cDag[i+0] = dataset[i+0]
+		cDag[i+1] = dataset[i+1]
+	}
+	return progpow(hash, nonce, uint64(len(dataset))*4, blockNumber, cDag, lookup)
+}
+
+func rotl32(x uint32, n uint32) uint32 {
+	return ((x) << (n % 32)) | ((x) >> (32 - (n % 32)))
+}
+
+func rotr32(x uint32, n uint32) uint32 {
+	return ((x) >> (n % 32)) | ((x) << (32 - (n % 32)))
+}
+
+func lower32(in uint64) uint32 {
+	return uint32(in)
+}
+
+func higher32(in uint64) uint32 {
+	return uint32(in >> 32)
+}
+
+var keccakfRNDC = [24]uint32{
+	0x00000001, 0x00008082, 0x0000808a, 0x80008000, 0x0000808b, 0x80000001,
+	0x80008081, 0x00008009, 0x0000008a, 0x00000088, 0x80008009, 0x8000000a,
+	0x8000808b, 0x0000008b, 0x00008089, 0x00008003, 0x00008002, 0x00000080,
+	0x0000800a, 0x8000000a, 0x80008081, 0x00008080, 0x80000001, 0x80008008}
+
+func keccakF800Round(st *[25]uint32, r int) {
+	var keccakfROTC = [24]uint32{1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 2,
+		14, 27, 41, 56, 8, 25, 43, 62, 18, 39, 61,
+		20, 44}
+	var keccakfPILN = [24]uint32{10, 7, 11, 17, 18, 3, 5, 16, 8, 21, 24,
+		4, 15, 23, 19, 13, 12, 2, 20, 14, 22, 9,
+		6, 1}
+	bc := make([]uint32, 5)
+	// Theta
+	for i := 0; i < 5; i++ {
+		bc[i] = st[i] ^ st[i+5] ^ st[i+10] ^ st[i+15] ^ st[i+20]
+	}
+
+	for i := 0; i < 5; i++ {
+		t := bc[(i+4)%5] ^ rotl32(bc[(i+1)%5], 1)
+		for j := 0; j < 25; j += 5 {
+			st[j+i] ^= t
+		}
+	}
+
+	// Rho Pi
+	t := st[1]
+	for i, j := range keccakfPILN {
+		bc[0] = st[j]
+		st[j] = rotl32(t, keccakfROTC[i])
+		t = bc[0]
+	}
+
+	//  Chi
+	for j := 0; j < 25; j += 5 {
+		bc[0] = st[j+0]
+		bc[1] = st[j+1]
+		bc[2] = st[j+2]
+		bc[3] = st[j+3]
+		bc[4] = st[j+4]
+		st[j+0] ^= ^bc[1] & bc[2]
+		st[j+1] ^= ^bc[2] & bc[3]
+		st[j+2] ^= ^bc[3] & bc[4]
+		st[j+3] ^= ^bc[4] & bc[0]
+		st[j+4] ^= ^bc[0] & bc[1]
+	}
+
+	//  Iota
+	st[0] ^= keccakfRNDC[r]
+	//return st
+}
+
+func keccakF800Short(headerHash []byte, nonce uint64, result []uint32) uint64 {
+	var st [25]uint32
+
+	for i := 0; i < 8; i++ {
+		st[i] = (uint32(headerHash[4*i])) +
+			(uint32(headerHash[4*i+1]) << 8) +
+			(uint32(headerHash[4*i+2]) << 16) +
+			(uint32(headerHash[4*i+3]) << 24)
+	}
+
+	st[8] = lower32(nonce)
+	st[9] = higher32(nonce)
+	for i := 0; i < 8; i++ {
+		st[10+i] = result[i]
+	}
+
+	for r := 0; r < 21; r++ {
+		keccakF800Round(&st, r)
+	}
+	keccakF800Round(&st, 21)
+	ret := make([]byte, 8)
+	binary.BigEndian.PutUint32(ret[4:], st[0])
+	binary.BigEndian.PutUint32(ret, st[1])
+	return binary.LittleEndian.Uint64(ret)
+}
+
+func keccakF800Long(headerHash []byte, nonce uint64, result []uint32) []byte {
+	var st [25]uint32
+
+	for i := 0; i < 8; i++ {
+		st[i] = (uint32(headerHash[4*i])) +
+			(uint32(headerHash[4*i+1]) << 8) +
+			(uint32(headerHash[4*i+2]) << 16) +
+			(uint32(headerHash[4*i+3]) << 24)
+	}
+
+	st[8] = lower32(nonce)
+	st[9] = higher32(nonce)
+	for i := 0; i < 8; i++ {
+		st[10+i] = result[i]
+	}
+
+	for r := 0; r <= 21; r++ {
+		keccakF800Round(&st, r)
+	}
+	ret := make([]byte, 32)
+	for i := 0; i < 8; i++ {
+		binary.LittleEndian.PutUint32(ret[i*4:], st[i])
+	}
+	return ret
+}
+
+func fnv1a(h *uint32, d uint32) uint32 {
+	*h = (*h ^ d) * uint32(0x1000193)
+	return *h
+}
+
+type kiss99State struct {
+	z     uint32
+	w     uint32
+	jsr   uint32
+	jcong uint32
+}
+
+func kiss99(st *kiss99State) uint32 {
+	var MWC uint32
+	st.z = 36969*(st.z&65535) + (st.z >> 16)
+	st.w = 18000*(st.w&65535) + (st.w >> 16)
+	MWC = ((st.z << 16) + st.w)
+	st.jsr ^= (st.jsr << 17)
+	st.jsr ^= (st.jsr >> 13)
+	st.jsr ^= (st.jsr << 5)
+	st.jcong = 69069*st.jcong + 1234567
+	return ((MWC ^ st.jcong) + st.jsr)
+}
+
+func fillMix(seed uint64, laneId uint32) [progpowRegs]uint32 {
+	var st kiss99State
+	var mix [progpowRegs]uint32
+
+	fnvHash := uint32(0x811c9dc5)
+
+	st.z = fnv1a(&fnvHash, lower32(seed))
+	st.w = fnv1a(&fnvHash, higher32(seed))
+	st.jsr = fnv1a(&fnvHash, laneId)
+	st.jcong = fnv1a(&fnvHash, laneId)
+
+	for i := 0; i < progpowRegs; i++ {
+		mix[i] = kiss99(&st)
+	}
+	return mix
+}
+
+// Merge new data from b into the value in a
+// Assuming A has high entropy only do ops that retain entropy
+// even if B is low entropy
+// (IE don't do A&B)
+func merge(a *uint32, b uint32, r uint32) {
+	switch r % 4 {
+	case 0:
+		*a = (*a * 33) + b
+	case 1:
+		*a = (*a ^ b) * 33
+	case 2:
+		*a = rotl32(*a, ((r>>16)%31)+1) ^ b
+	default:
+		*a = rotr32(*a, ((r>>16)%31)+1) ^ b
+	}
+}
+
+func progpowInit(seed uint64) (kiss99State, [progpowRegs]uint32, [progpowRegs]uint32) {
+	var randState kiss99State
+
+	fnvHash := uint32(0x811c9dc5)
+
+	randState.z = fnv1a(&fnvHash, lower32(seed))
+	randState.w = fnv1a(&fnvHash, higher32(seed))
+	randState.jsr = fnv1a(&fnvHash, lower32(seed))
+	randState.jcong = fnv1a(&fnvHash, higher32(seed))
+
+	// Create a random sequence of mix destinations for merge()
+	// and mix sources for cache reads
+	// guarantees every destination merged once
+	// guarantees no duplicate cache reads, which could be optimized away
+	// Uses Fisher-Yates shuffle
+	var dstSeq = [32]uint32{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31}
+	var srcSeq = [32]uint32{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31}
+
+	for i := uint32(progpowRegs - 1); i > 0; i-- {
+		j := kiss99(&randState) % (i + 1)
+		dstSeq[i], dstSeq[j] = dstSeq[j], dstSeq[i]
+		j = kiss99(&randState) % (i + 1)
+		srcSeq[i], srcSeq[j] = srcSeq[j], srcSeq[i]
+	}
+	return randState, dstSeq, srcSeq
+}
+
+// Random math between two input values
+func progpowMath(a uint32, b uint32, r uint32) uint32 {
+	switch r % 11 {
+	case 0:
+		return a + b
+	case 1:
+		return a * b
+	case 2:
+		return higher32(uint64(a) * uint64(b))
+	case 3:
+		if a < b {
+			return a
+		}
+		return b
+	case 4:
+		return rotl32(a, b)
+	case 5:
+		return rotr32(a, b)
+	case 6:
+		return a & b
+	case 7:
+		return a | b
+	case 8:
+		return a ^ b
+	case 9:
+		return uint32(bits.LeadingZeros32(a) + bits.LeadingZeros32(b))
+	case 10:
+		return uint32(bits.OnesCount32(a) + bits.OnesCount32(b))
+
+	default:
+		return 0
+	}
+}
+
+func progpowLoop(seed uint64, loop uint32, mix *[progpowLanes][progpowRegs]uint32,
+	lookup func(index uint32) []byte,
+	cDag []uint32, datasetSize uint32) {
+	// All lanes share a base address for the global load
+	// Global offset uses mix[0] to guarantee it depends on the load result
+	gOffset := mix[loop%progpowLanes][0] % (64 * datasetSize / (progpowLanes * progpowDagLoads))
+
+	var (
+		srcCounter = uint32(0)
+		dstCounter = uint32(0)
+		randState  kiss99State
+		srcSeq     [32]uint32
+		dstSeq     [32]uint32
+		rnd        = kiss99
+		//iMax       = uint32(0)
+		index           = uint32(0)
+		data_g []uint32 = make([]uint32, progpowDagLoads)
+	)
+	// 256 bytes of dag data
+	dag_item := make([]byte, 256)
+	// The lookup returns 64, so we'll fetch four items
+	copy(dag_item, lookup((gOffset*progpowLanes)*progpowDagLoads))
+	copy(dag_item[64:], lookup((gOffset*progpowLanes)*progpowDagLoads+16))
+	copy(dag_item[128:], lookup((gOffset*progpowLanes)*progpowDagLoads+32))
+	copy(dag_item[192:], lookup((gOffset*progpowLanes)*progpowDagLoads+48))
+
+	// Lanes can execute in parallel and will be convergent
+	for l := uint32(0); l < progpowLanes; l++ {
+
+		// initialize the seed and mix destination sequence
+		randState, dstSeq, srcSeq = progpowInit(seed)
+		srcCounter = uint32(0)
+		dstCounter = uint32(0)
+
+		//if progpowCntCache > progpowCntMath {
+		//	iMax = progpowCntCache
+		//} else {
+		//	iMax = progpowCntMath
+		//}
+
+		for i := uint32(0); i < progpowCntMath; i++ {
+			if i < progpowCntCache {
+				// Cached memory access
+				// lanes access random location
+
+				src := srcSeq[(srcCounter)%progpowRegs]
+				srcCounter++
+
+				offset := mix[l][src] % progpowCacheWords
+				data32 := cDag[offset]
+
+				dst := dstSeq[(dstCounter)%progpowRegs]
+				dstCounter++
+
+				r := kiss99(&randState)
+				merge(&mix[l][dst], data32, r)
+			}
+
+			//if i < progpowCntMath
+			{
+				// Random Math
+				srcRnd := rnd(&randState) % (progpowRegs * (progpowRegs - 1))
+				src1 := srcRnd % progpowRegs
+				src2 := srcRnd / progpowRegs
+				if src2 >= src1 {
+					src2++
+				}
+				data32 := progpowMath(mix[l][src1], mix[l][src2], rnd(&randState))
+
+				dst := dstSeq[(dstCounter)%progpowRegs]
+				dstCounter++
+
+				merge(&mix[l][dst], data32, rnd(&randState))
+			}
+		}
+		index = ((l ^ loop) % progpowLanes) * progpowDagLoads
+
+		data_g[0] = binary.LittleEndian.Uint32(dag_item[4*index:])
+		data_g[1] = binary.LittleEndian.Uint32(dag_item[4*(index+1):])
+		data_g[2] = binary.LittleEndian.Uint32(dag_item[4*(index+2):])
+		data_g[3] = binary.LittleEndian.Uint32(dag_item[4*(index+3):])
+
+		merge(&mix[l][0], data_g[0], rnd(&randState))
+
+		for i := 1; i < progpowDagLoads; i++ {
+			dst := dstSeq[(dstCounter)%progpowRegs]
+			dstCounter++
+			merge(&mix[l][dst], data_g[i], rnd(&randState))
+		}
+	}
+}
+
+func progpow(hash []byte, nonce uint64, size uint64, blockNumber uint64, cDag []uint32,
+	lookup func(index uint32) []byte) ([]byte, []byte) {
+	var (
+		mix         [progpowLanes][progpowRegs]uint32
+		laneResults [progpowLanes]uint32
+	)
+	result := make([]uint32, 8)
+	seed := keccakF800Short(hash, nonce, result)
+	for lane := uint32(0); lane < progpowLanes; lane++ {
+		mix[lane] = fillMix(seed, lane)
+	}
+	period := (blockNumber / progpowPeriodLength)
+	for l := uint32(0); l < progpowCntDag; l++ {
+		progpowLoop(period, l, &mix, lookup, cDag, uint32(size/progpowMixBytes))
+	}
+
+	// Reduce mix data to a single per-lane result
+	for lane := uint32(0); lane < progpowLanes; lane++ {
+		laneResults[lane] = 0x811c9dc5
+		for i := uint32(0); i < progpowRegs; i++ {
+			fnv1a(&laneResults[lane], mix[lane][i])
+		}
+	}
+	for i := uint32(0); i < 8; i++ {
+		result[i] = 0x811c9dc5
+	}
+	for lane := uint32(0); lane < progpowLanes; lane++ {
+		fnv1a(&result[lane%8], laneResults[lane])
+	}
+	finalHash := keccakF800Long(hash, seed, result[:])
+	mixHash := make([]byte, 8*4)
+	for i := 0; i < 8; i++ {
+		binary.LittleEndian.PutUint32(mixHash[i*4:], result[i])
+	}
+	return mixHash[:], finalHash[:]
+}
diff --git a/consensus/ethash/progpow_test.go b/consensus/ethash/progpow_test.go
new file mode 100644
index 000000000..c2ba7865c
--- /dev/null
+++ b/consensus/ethash/progpow_test.go
@@ -0,0 +1,284 @@
+// Copyright 2018 The go-ethereum Authors
+// This file is part of go-ethereum.
+//
+// go-ethereum is free software: you can redistribute it and/or modify
+// it under the terms of the GNU General Public License as published by
+// the Free Software Foundation, either version 3 of the License, or
+// (at your option) any later version.
+//
+// go-ethereum is distributed in the hope that it will be useful,
+// but WITHOUT ANY WARRANTY; without even the implied warranty of
+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+// GNU General Public License for more details.
+//
+// You should have received a copy of the GNU General Public License
+// along with go-ethereum. If not, see <http://www.gnu.org/licenses/>.
+
+package ethash
+
+import (
+	"bytes"
+	"encoding/json"
+	"fmt"
+	"io/ioutil"
+	"path/filepath"
+	"strconv"
+	"testing"
+
+	"github.com/ethereum/go-ethereum/common"
+	"golang.org/x/crypto/sha3"
+)
+
+func TestRandomMerge(t *testing.T) {
+
+	type test struct {
+		a   uint32
+		b   uint32
+		exp uint32
+	}
+	for i, tt := range []test{
+		{1000000, 101, 33000101},
+		{2000000, 102, 66003366},
+		{3000000, 103, 6000103},
+		{4000000, 104, 2000104},
+		{1000000, 0, 33000000},
+		{2000000, 0, 66000000},
+		{3000000, 0, 6000000},
+		{4000000, 0, 2000000},
+	} {
+		res := tt.a
+		merge(&res, tt.b, uint32(i))
+		if res != tt.exp {
+			t.Errorf("test %d, expected %d, got %d", i, tt.exp, res)
+		}
+	}
+
+}
+
+func TestProgpowChanges(t *testing.T) {
+	headerHash := common.HexToHash("ffeeddccbbaa9988776655443322110000112233445566778899aabbccddeeff")
+	nonce := uint64(0x123456789abcdef0)
+	blocknum := uint64(30000)
+	seed := seedHash(blocknum)
+	fmt.Printf("seedHash %x\n", seed)
+	//seed =  common.FromHex("ee304846ddd0a47b")
+	expCdag0_to_15 := []uint32{
+		0xb3e35467, 0xae7402e3, 0x8522a782, 0xa2d8353b,
+		0xff4723bd, 0xbfbc05ee, 0xde6944de, 0xf0d2b5b8,
+		0xc74cbad3, 0xb100f797, 0x05bc60be, 0x4f40840b,
+		0x35e47268, 0x9cd6f993, 0x6a0e4659, 0xb838e46e,
+	}
+	expCdag4080_to_4095 := []uint32{
+		0xbde0c650, 0x57cba482, 0x54877c9d, 0xf9fdc423,
+		0xfb65141b, 0x55074ca4, 0xc7dd116e, 0xbc1737d1,
+		0x126e8847, 0xb16983b2, 0xf80c058e, 0xe0ad53b5,
+		0xd5f3e840, 0xff1bdd89, 0x35660a19, 0x73244193,
+	}
+	epoch := blocknum / epochLength
+	size := cacheSize(blocknum)
+	cache := make([]uint32, size/4)
+	generateCache(cache, epoch, seed)
+	cDag := make([]uint32, progpowCacheWords)
+	generateCDag(cDag, cache, epoch)
+
+	for i := 0; i < 15; i++ {
+		if exp := expCdag0_to_15[i]; exp != cDag[i] {
+			t.Errorf("test %d, exp %x != %x", i, exp, cDag[i])
+
+		}
+		if exp := expCdag4080_to_4095[i]; exp != cDag[4080+i] {
+			t.Errorf("test %d (+4080), exp %x != %x", i, exp, cDag[4080+i])
+		}
+	}
+	mixHash, finalHash, _ := hashForBlock(blocknum, nonce, headerHash)
+	fmt.Printf("mixHash %x\n", mixHash)
+	fmt.Printf("finalHash %x\n", finalHash)
+	expMix := common.FromHex("11f19805c58ab46610ff9c719dcf0a5f18fa2f1605798eef770c47219274767d")
+	expHash := common.FromHex("5b7ccd472dbefdd95b895cac8ece67ff0deb5a6bd2ecc6e162383d00c3728ece")
+	if !bytes.Equal(expMix, mixHash) {
+		t.Errorf("mixhash err, expected %x, got %x", expMix, mixHash)
+	}
+	if !bytes.Equal(expHash, finalHash) {
+		t.Errorf("finhash err, expected %x, got %x", expHash, finalHash)
+	}
+	//digest: 7d9a5f6b1407796497f16b091e5dcbbcd711d025634b505fae496611c0d6f57d
+	//result (top 64 bits): 6cf196600abd663e
+}
+
+func TestCDag(t *testing.T) {
+	size := cacheSize(0)
+	cache := make([]uint32, size/4)
+	seed := seedHash(0)
+	generateCache(cache, 0, seed)
+	cDag := make([]uint32, progpowCacheWords)
+	generateCDag(cDag, cache, 0)
+	//fmt.Printf("Cdag: %d \n", cDag[:20])
+	expect := []uint32{690150178, 1181503948, 2248155602, 2118233073, 2193871115,
+		1791778428, 1067701239, 724807309, 530799275, 3480325829, 3899029234,
+		1998124059, 2541974622, 1100859971, 1297211151, 3268320000, 2217813733,
+		2690422980, 3172863319, 2651064309}
+	for i, v := range cDag[:20] {
+		if expect[i] != v {
+			t.Errorf("cdag err, index %d, expected %d, got %d", i, expect[i], v)
+		}
+	}
+}
+
+func TestRandomMath(t *testing.T) {
+
+	type test struct {
+		a   uint32
+		b   uint32
+		exp uint32
+	}
+	for i, tt := range []test{
+		{20, 22, 42},
+		{70000, 80000, 1305032704},
+		{70000, 80000, 1},
+		{1, 2, 1},
+		{3, 10000, 196608},
+		{3, 0, 3},
+		{3, 6, 2},
+		{3, 6, 7},
+		{3, 6, 5},
+		{0, 0xffffffff, 32},
+		{3 << 13, 1 << 5, 3},
+		{22, 20, 42},
+		{80000, 70000, 1305032704},
+		{80000, 70000, 1},
+		{2, 1, 1},
+		{10000, 3, 80000},
+		{0, 3, 0},
+		{6, 3, 2},
+		{6, 3, 7},
+		{6, 3, 5},
+		{0, 0xffffffff, 32},
+		{3 << 13, 1 << 5, 3},
+	} {
+		res := progpowMath(tt.a, tt.b, uint32(i))
+		if res != tt.exp {
+			t.Errorf("test %d, expected %d, got %d", i, tt.exp, res)
+		}
+	}
+}
+
+func TestProgpowKeccak256(t *testing.T) {
+	result := make([]uint32, 8)
+	header := make([]byte, 32)
+	hash := keccakF800Long(header, 0, result)
+	exp := "5dd431e5fbc604f499bfa0232f45f8f142d0ff5178f539e5a7800bf0643697af"
+	if !bytes.Equal(hash, common.FromHex(exp)) {
+		t.Errorf("expected %s, got %x", exp, hash)
+	}
+}
+func TestProgpowKeccak64(t *testing.T) {
+	result := make([]uint32, 8)
+	header := make([]byte, 32)
+	hash := keccakF800Short(header, 0, result)
+	exp := uint64(0x5dd431e5fbc604f4)
+	if exp != hash {
+		t.Errorf("expected %x, got %x", exp, hash)
+	}
+}
+
+func hashForBlock(blocknum uint64, nonce uint64, headerHash common.Hash) ([]byte, []byte, error) {
+	return speedyHashForBlock(&periodContext{}, blocknum, nonce, headerHash)
+}
+
+type periodContext struct {
+	cDag        []uint32
+	cache       []uint32
+	datasetSize uint64
+	blockNum    uint64
+}
+
+// speedyHashForBlock reuses the context, if possible
+func speedyHashForBlock(ctx *periodContext, blocknum uint64, nonce uint64, headerHash common.Hash) ([]byte, []byte, error) {
+	if blocknum == 0 || ctx.blockNum/epochLength != blocknum/epochLength {
+		size := cacheSize(blocknum)
+		cache := make([]uint32, size/4)
+		seed := seedHash(blocknum)
+		epoch := blocknum / epochLength
+		generateCache(cache, epoch, seed)
+		cDag := make([]uint32, progpowCacheWords)
+		generateCDag(cDag, cache, epoch)
+		ctx.cache = cache
+		ctx.cDag = cDag
+		ctx.datasetSize = datasetSize(blocknum)
+		ctx.blockNum = blocknum
+
+	}
+	keccak512 := makeHasher(sha3.NewLegacyKeccak512())
+	lookup := func(index uint32) []byte {
+		x := generateDatasetItem(ctx.cache, index/16, keccak512)
+		//fmt.Printf("lookup(%d) : %x\n", index/16, x)
+		return x
+	}
+	mixhash, final := progpow(headerHash.Bytes(), nonce, ctx.datasetSize, blocknum, ctx.cDag, lookup)
+	return mixhash, final, nil
+}
+
+func TestProgpowHash(t *testing.T) {
+	mixHash, finalHash, _ := hashForBlock(0, 0, common.Hash{})
+	expHash := common.FromHex("63155f732f2bf556967f906155b510c917e48e99685ead76ea83f4eca03ab12b")
+	expMix := common.FromHex("faeb1be51075b03a4ff44b335067951ead07a3b078539ace76fd56fc410557a3")
+	if !bytes.Equal(mixHash, expMix) {
+		t.Errorf("mixhash err, got %x expected %x", mixHash, expMix)
+	}
+	if !bytes.Equal(finalHash, expHash) {
+		t.Errorf("sealhash err, got %x expected %x", finalHash, expHash)
+	}
+}
+
+type progpowHashTestcase struct {
+	blockNum   int
+	headerHash string
+	nonce      string
+	mixHash    string
+	finalHash  string
+}
+
+func (n *progpowHashTestcase) UnmarshalJSON(buf []byte) error {
+	tmp := []interface{}{&n.blockNum, &n.headerHash, &n.nonce, &n.mixHash, &n.finalHash}
+	wantLen := len(tmp)
+	if err := json.Unmarshal(buf, &tmp); err != nil {
+		return err
+	}
+	if g, e := len(tmp), wantLen; g != e {
+		return fmt.Errorf("wrong number of fields in testcase: %d != %d", g, e)
+	}
+	return nil
+}
+func TestProgpowHashes(t *testing.T) {
+	data, err := ioutil.ReadFile(filepath.Join(".", "testdata", "progpow_testvectors.json"))
+	if err != nil {
+		t.Fatal(err)
+	}
+	var tests []progpowHashTestcase
+	if err = json.Unmarshal(data, &tests); err != nil {
+		t.Fatal(err)
+	}
+	var ctx periodContext
+	for i, tt := range tests {
+		nonce, err := strconv.ParseInt(tt.nonce, 16, 64)
+		if err != nil {
+			t.Errorf("test %d, nonce err: %v", i, err)
+		}
+		mixhash, final, err := speedyHashForBlock(&ctx,
+			uint64(tt.blockNum),
+			uint64(nonce),
+			common.BytesToHash(common.FromHex(tt.headerHash)))
+		if err != nil {
+			t.Errorf("test %d, err: %v", i, err)
+		}
+		expectFinalHash := common.FromHex(tt.finalHash)
+		expectMixHash := common.FromHex(tt.mixHash)
+		if !bytes.Equal(final, expectFinalHash) {
+			t.Errorf("test %d (blocknum %d), sealhash err, got %x expected %x", i, tt.blockNum, final, expectFinalHash)
+		}
+		if !bytes.Equal(mixhash, expectMixHash) {
+			t.Fatalf("test %d (blocknum %d), mixhash err, got %x expected %x", i, tt.blockNum, mixhash, expectMixHash)
+		}
+		//fmt.Printf("test %d ok!\n", i)
+	}
+}
diff --git a/consensus/ethash/sealer.go b/consensus/ethash/sealer.go
index 3a0919ca9..feaf9b696 100644
--- a/consensus/ethash/sealer.go
+++ b/consensus/ethash/sealer.go
@@ -137,6 +137,7 @@ func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan s
 		target  = new(big.Int).Div(two256, header.Difficulty)
 		number  = header.Number.Uint64()
 		dataset = ethash.dataset(number, false)
+		powFull = ethash.fullPow(header.Number)
 	)
 	// Start generating random nonces until we abort or find a good one
 	var (
@@ -162,7 +163,7 @@ search:
 				attempts = 0
 			}
 			// Compute the PoW value of this nonce
-			digest, result := hashimotoFull(dataset.dataset, hash, nonce)
+			digest, result := powFull(dataset.dataset, hash, nonce, number)
 			if new(big.Int).SetBytes(result).Cmp(target) <= 0 {
 				// Correct nonce found, create a new header with it
 				header = types.CopyHeader(header)
diff --git a/consensus/ethash/testdata/progpow_testvectors.json b/consensus/ethash/testdata/progpow_testvectors.json
new file mode 100644
index 000000000..87a6a3b7a
--- /dev/null
+++ b/consensus/ethash/testdata/progpow_testvectors.json
@@ -0,0 +1,38 @@
+[
+  [0, "0000000000000000000000000000000000000000000000000000000000000000", "0000000000000000",
+    "faeb1be51075b03a4ff44b335067951ead07a3b078539ace76fd56fc410557a3",
+    "63155f732f2bf556967f906155b510c917e48e99685ead76ea83f4eca03ab12b"],
+  [49, "63155f732f2bf556967f906155b510c917e48e99685ead76ea83f4eca03ab12b", "0000000006ff2c47",
+    "c789c1180f890ec555ff42042913465481e8e6bc512cb981e1c1108dc3f2227d",
+    "9e7248f20914913a73d80a70174c331b1d34f260535ac3631d770e656b5dd922"],
+  [50, "9e7248f20914913a73d80a70174c331b1d34f260535ac3631d770e656b5dd922", "00000000076e482e",
+    "c7340542c2a06b3a7dc7222635f7cd402abf8b528ae971ddac6bbe2b0c7cb518",
+    "de37e1824c86d35d154cf65a88de6d9286aec4f7f10c3fc9f0fa1bcc2687188d"],
+  [99, "de37e1824c86d35d154cf65a88de6d9286aec4f7f10c3fc9f0fa1bcc2687188d", "000000003917afab",
+    "f5e60b2c5bfddd136167a30cbc3c8dbdbd15a512257dee7964e0bc6daa9f8ba7",
+    "ac7b55e801511b77e11d52e9599206101550144525b5679f2dab19386f23dcce"],
+  [29950, "ac7b55e801511b77e11d52e9599206101550144525b5679f2dab19386f23dcce", "005d409dbc23a62a",
+    "07393d15805eb08ee6fc6cb3ad4ad1010533bd0ff92d6006850246829f18fd6e",
+    "e43d7e0bdc8a4a3f6e291a5ed790b9fa1a0948a2b9e33c844888690847de19f5"],
+  [29999, "e43d7e0bdc8a4a3f6e291a5ed790b9fa1a0948a2b9e33c844888690847de19f5", "005db5fa4c2a3d03",
+    "7551bddf977491da2f6cfc1679299544b23483e8f8ee0931c4c16a796558a0b8",
+    "d34519f72c97cae8892c277776259db3320820cb5279a299d0ef1e155e5c6454"],
+  [30000, "d34519f72c97cae8892c277776259db3320820cb5279a299d0ef1e155e5c6454", "005db8607994ff30",
+    "f1c2c7c32266af9635462e6ce1c98ebe4e7e3ecab7a38aaabfbf2e731e0fbff4",
+    "8b6ce5da0b06d18db7bd8492d9e5717f8b53e7e098d9fef7886d58a6e913ef64"],
+  [30049, "8b6ce5da0b06d18db7bd8492d9e5717f8b53e7e098d9fef7886d58a6e913ef64", "005e2e215a8ca2e7",
+    "57fe6a9fbf920b4e91deeb66cb0efa971e08229d1a160330e08da54af0689add",
+    "c2c46173481b9ced61123d2e293b42ede5a1b323210eb2a684df0874ffe09047"],
+  [30050, "c2c46173481b9ced61123d2e293b42ede5a1b323210eb2a684df0874ffe09047", "005e30899481055e",
+    "ba30c61cc5a2c74a5ecaf505965140a08f24a296d687e78720f0b48baf712f2d",
+    "ea42197eb2ba79c63cb5e655b8b1f612c5f08aae1a49ff236795a3516d87bc71"],
+  [30099, "ea42197eb2ba79c63cb5e655b8b1f612c5f08aae1a49ff236795a3516d87bc71", "005ea6aef136f88b",
+    "cfd5e46048cd133d40f261fe8704e51d3f497fc14203ac6a9ef6a0841780b1cd",
+    "49e15ba4bf501ce8fe8876101c808e24c69a859be15de554bf85dbc095491bd6"],
+  [59950, "49e15ba4bf501ce8fe8876101c808e24c69a859be15de554bf85dbc095491bd6", "02ebe0503bd7b1da",
+    "21511fbaa31fb9f5fc4998a754e97b3083a866f4de86fa7500a633346f56d773",
+    "f5c50ba5c0d6210ddb16250ec3efda178de857b2b1703d8d5403bd0f848e19cf"],
+  [59999, "f5c50ba5c0d6210ddb16250ec3efda178de857b2b1703d8d5403bd0f848e19cf", "02edb6275bd221e3",
+    "653eda37d337e39d311d22be9bbd3458d3abee4e643bee4a7280a6d08106ef98",
+    "341562d10d4afb706ec2c8d5537cb0c810de02b4ebb0a0eea5ae335af6fb2e88"]
+]
\ No newline at end of file
diff --git a/eth/backend.go b/eth/backend.go
index 6710e4513..511dadeca 100644
--- a/eth/backend.go
+++ b/eth/backend.go
@@ -247,7 +247,7 @@ func CreateConsensusEngine(ctx *node.ServiceContext, chainConfig *params.ChainCo
 		return ethash.NewTester(nil, noverify)
 	case ethash.ModeShared:
 		log.Warn("Ethash used in shared mode")
-		return ethash.NewShared()
+		return ethash.NewShared(chainConfig.ProgpowBlock)
 	default:
 		engine := ethash.New(ethash.Config{
 			CacheDir:       ctx.ResolvePath(config.CacheDir),
@@ -256,6 +256,7 @@ func CreateConsensusEngine(ctx *node.ServiceContext, chainConfig *params.ChainCo
 			DatasetDir:     config.DatasetDir,
 			DatasetsInMem:  config.DatasetsInMem,
 			DatasetsOnDisk: config.DatasetsOnDisk,
+			ProgpowBlock:   chainConfig.ProgpowBlock,
 		}, notify, noverify)
 		engine.SetThreads(-1) // Disable CPU mining
 		return engine
diff --git a/params/config.go b/params/config.go
index 44b2ffeba..c09e73458 100644
--- a/params/config.go
+++ b/params/config.go
@@ -141,16 +141,16 @@ var (
 	//
 	// This configuration is intentionally not using keyed fields to force anyone
 	// adding flags to the config to also have to set these fields.
-	AllEthashProtocolChanges = &ChainConfig{big.NewInt(1337), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, new(EthashConfig), nil}
+	AllEthashProtocolChanges = &ChainConfig{big.NewInt(1337), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, nil, new(EthashConfig), nil}
 
 	// AllCliqueProtocolChanges contains every protocol change (EIPs) introduced
 	// and accepted by the Ethereum core developers into the Clique consensus.
 	//
 	// This configuration is intentionally not using keyed fields to force anyone
 	// adding flags to the config to also have to set these fields.
-	AllCliqueProtocolChanges = &ChainConfig{big.NewInt(1337), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, nil, &CliqueConfig{Period: 0, Epoch: 30000}}
+	AllCliqueProtocolChanges = &ChainConfig{big.NewInt(1337), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, nil, nil, &CliqueConfig{Period: 0, Epoch: 30000}}
 
-	TestChainConfig = &ChainConfig{big.NewInt(1), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, new(EthashConfig), nil}
+	TestChainConfig = &ChainConfig{big.NewInt(1), big.NewInt(0), nil, false, big.NewInt(0), common.Hash{}, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, nil, new(EthashConfig), nil}
 	TestRules       = TestChainConfig.Rules(new(big.Int))
 )
 
@@ -190,6 +190,7 @@ type ChainConfig struct {
 	ConstantinopleBlock *big.Int `json:"constantinopleBlock,omitempty"` // Constantinople switch block (nil = no fork, 0 = already activated)
 	PetersburgBlock     *big.Int `json:"petersburgBlock,omitempty"`     // Petersburg switch block (nil = same as Constantinople)
 	EWASMBlock          *big.Int `json:"ewasmBlock,omitempty"`          // EWASM switch block (nil = no fork, 0 = already activated)
+	ProgpowBlock        *big.Int `json:"progpowBlock,omitempty"`        // Progpow switch block (nil = not active, 0 = already activated)
 
 	// Various consensus engines
 	Ethash *EthashConfig `json:"ethash,omitempty"`
@@ -226,7 +227,7 @@ func (c *ChainConfig) String() string {
 	default:
 		engine = "unknown"
 	}
-	return fmt.Sprintf("{ChainID: %v Homestead: %v DAO: %v DAOSupport: %v EIP150: %v EIP155: %v EIP158: %v Byzantium: %v Constantinople: %v  ConstantinopleFix: %v Engine: %v}",
+	return fmt.Sprintf("{ChainID: %v Homestead: %v DAO: %v DAOSupport: %v EIP150: %v EIP155: %v EIP158: %v Byzantium: %v Constantinople: %v ConstantinopleFix: %v Progpow: %v Engine: %v}",
 		c.ChainID,
 		c.HomesteadBlock,
 		c.DAOForkBlock,
@@ -237,6 +238,7 @@ func (c *ChainConfig) String() string {
 		c.ByzantiumBlock,
 		c.ConstantinopleBlock,
 		c.PetersburgBlock,
+		c.ProgpowBlock,
 		engine,
 	)
 }
diff --git a/tests/block_test_util.go b/tests/block_test_util.go
index 9fa69bf4e..9cb47569a 100644
--- a/tests/block_test_util.go
+++ b/tests/block_test_util.go
@@ -116,7 +116,7 @@ func (t *BlockTest) Run() error {
 	if t.json.SealEngine == "NoProof" {
 		engine = ethash.NewFaker()
 	} else {
-		engine = ethash.NewShared()
+		engine = ethash.NewShared(nil)
 	}
 	chain, err := core.NewBlockChain(db, &core.CacheConfig{TrieCleanLimit: 0}, config, engine, vm.Config{}, nil)
 	if err != nil {
